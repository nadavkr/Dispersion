\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage[dvipsnames,usenames]{color}
\usepackage[colorlinks=true,urlcolor=Blue,citecolor=Green,linkcolor=BrickRed]{hyperref}
\usepackage[usenames,dvipsnames]{xcolor}
\urlstyle{same}

\usepackage{amsthm,amsmath,amssymb,mathabx}
\usepackage{fullpage}
\usepackage[ruled,noend,linesnumbered]{algorithm2e}     
\usepackage{enumerate,comment}
\usepackage{url}
\usepackage[capitalise]{cleveref}
\usepackage{todonotes}
\usepackage{tikz}
\usepackage[noadjust]{cite}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsfonts}
\usepackage{color}
\usepackage{array}

%\pagestyle{plain}

\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\poly}{\text{poly}}

\newcommand{\Oh}{{O}}

% For cleverref compatibility
\newtheorem{theorem}{Theorem}[section]
\newtheorem{algo}{Algorithm}[section]
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{observation}{Observation}
\newtheorem{fact}[theorem]{Fact}
\theoremstyle{definition}   
\newtheorem{definition}{Definition}
\usepackage{authblk}
\theoremstyle{remark}
\newtheorem{example}[theorem]{Example}
\newtheorem*{claim}{Claim}
\newtheorem{case}{Case}
\newtheorem{step}{Step}[section]

\newtheorem{property}[theorem]{Property}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\begin{document}

\title{Dispersion on Trees}
\author[1]{}
\affil[1]{University of Haifa, Israel}


\date{}
\maketitle

\begin{abstract}
In the dispersion problem we want to select $k$ nodes of a given graph as to maximize
the minimum distance between any two chosen nodes. This can be seen as a generalization
of the independent set problem, where the goal is to select nodes so that the minimum distance
is larger than 1.
We design an optimal $\Oh(n)$ time algorithm for the dispersion problem on trees consisting
of $n$ nodes, thus improving the previous $\Oh(n\log n)$ time solution. 

Then we consider the weighted version. 
For the decision
version, where the goal is to find a set of nodes of
total weight at least $k$ such that any two nodes are at distance at least $\lambda$, we present tight $\Theta(n\log n)$ upper and lower bounds. For the optimization version, where we wish to maximize  $\lambda$, we present an
 $\Oh(n\log^2n)$ upper bound improving the previous $\Oh(n\log^4 n)$ time solution. 
\end{abstract}

\section{Introduction}
Facility location is a family of problems, where the goal is to place
a number of facilities as to minimize the total cost while preserving
given constraints. In its basic version, called the metric $k$-center
problem, we wish to designate up to $k$ nodes of a given weighted graph
to be facilities, as to minimize the maximum distance of a node to its
closes facility. Even this simplest version is already NP-hard \cite{Vazirani2003}. However, a simple greedy 2-approximation algorithm is known \cite{Gonzalez1985}. The situation for different
objective functions or more restrictions on the placement is of course
more complex, but nevertheless one can often design an efficient
approximation algorithm, see \cite{DavidB.Shmoys1997} and  references
therein.

Given that facility location problems are usually if not always
NP-hard, it makes sense to consider them on restricted 
graphs families. The simplest yet still non-trivial such a family are trees on
$n$ nodes. There are multiple possible versions of the $k$-center
problem on trees: the facilities can be either only the nodes of the
tree or any points on an edge, and we might either minimize the
distance of any node or any point on an edge to its closest facility.
All these versions have been extensively studied, culminating in an
$\Oh(n)$ time and space algorithm given by Frederickson \cite{Frederickson1991a} that
solves all but one of them. This was an improvement on the previous
$\Oh(n\log n)$ time algorithm by Frederickson and Johnson \cite{Frederickson1983}, which in turn was an improvement
on the $\Oh(n\log^2n)$ time algorithm of Megiddo et al. \cite{Megiddo1981}. 

The weighted version
of these problems has also been studied. In this version, every node has an associated weight and the
distance is multiplied by the corresponding weight. The currently fastest solution is the $\Oh(n\log^2n)$ time algorithm of Megiddo and Tamir %cite Cole and
\cite{Megiddo1983}. Among the facility location problems on trees there
is the max-min tree $k$-partitioning \cite{Perl1981} and the min-max tree
$k$-partitioning \cite{Becker1982}, both solved by Frederickson in $\Oh(n)$ time
\cite{Frederickson1991} using a clever approach based on the parametric search that
he has later extended to solve the $k$-center problem.

In this paper we focus on the max-min tree $k$-dispersion problem that falls within the class of facility
location problems on trees. In this problem, the goal
is to select $k$ nodes so as to maximize the minimum distance between any
two chosen nodes. In other words, we wish to select $k$ nodes that are as spread-apart as possible. 
This generalizes the maximum independent set
problem by binary searching for the largest value of $k$ for which the
minimum distance is at least 2. The best previously known algorithm
for the max-min tree $k$-dispersion was given by Bhattacharya and Houle
\cite{Bhattacharya1991} and takes $\Oh(n\log n)$ time, improving on an earlier $\Oh(kn+n\log n)$
solution for the one dimensional case given by Wang and Kuo~\cite{Wang1988} . Using the
framework of Frederickson, we construct an optimal $\Oh(n)$ time algorithm
for this problem. In our solution we also develop a slightly modified
version of this framework, which might be simpler to understand. Then
we move the weighted version, where the goal is to select nodes with
 total weight  at last $k$. There, the best previously known
solution requires $\Oh(n\log^4 n)$ time \cite{Bhattacharya1991}. We present a significantly
faster $\Oh(n\log^2 n)$ time algorithm. We also show that the decision
version, where the goal is to check if there exists a set of of nodes
total weight $k$ such that any two nodes are at distance at least $b$,
requires $\Omega(n\log n)$ time in the algebraic decision tree model. We
also present a matching $\Oh(n\log n)$ time algorithm, which is then used
to construct our $\Oh(n\log^2n)$ time solution for the weighted max-min
tree $k$-dispersion using the standard parametric search paradigm of Fredrickson. 

\section{Preliminaries}

For a subset of nodes $P\subseteq V$, let $d(u,v)$ denote the distance between nodes $u$ and $v$ and let $f(P)=min_{u,v\in P} \{d(u,v)\}$. The problems we solve are formally defined as: 

\begin{enumerate}
\item {\bf The Dispersion Optimization Problem:} Given a tree $T$ with non-negative edge lengths, and a  number $p$, find a subset $P\subseteq V$ of size $p$ s.t.  $f(P)$ is maximized. 

\item {\bf The Dispersion Decision Problem:}  Given a tree $T$ with non-negative edge lengths, a number $p$, and a number $\lambda$, find a subset $P\subseteq V$ of size $p$ s.t. $f(P)\geq\lambda$.
\end{enumerate}

\noindent The optimization problem is called {\em MMDP} and the decision version is called the {\em feasibility test}.
%
%\begin{definition}
%\emph{Max-Min Dispersion Problem (MMDP)} Given a tree $T$ with non-negative edge lengths, and a natural number $p$, find a subset $P\subseteq V$ of size $p$ s.t. $f(P)=min{\scriptscriptstyle \forall u,v\in P,u\neq v}d(u,v)$ is maximized.
%\end{definition}
%\begin{definition}
%\emph{MMDP Feasibility Test} Given a MMDP instance and a number $\lambda\geq0$ decide if there exists a subset $P\subseteq V$ of size $p$ s.t. $f(P)\geq\lambda$.
%\end{definition}
%
\section{The unweighted case}
We first describe how to solve the feasibility test in linear time, and then use this algorithm to solve the MMDP.
\subsection{Linear algorithm for the MMDP Feasibility Test}\label{linear F.T.}
%\begin{algo} \label{unWeightedFeasibilityAlgo}
We show a recursive linear algorithm.
At each step of the recursion, we would like to provide the maximal valid solution for the current subtree, given some $\lambda$. I.e, we would like to return $P$, a maximal subset of the vertices of the subtree, s.t. $f(P)\geq\lambda$.
We are given a root vertex $v$ and its children nodes $v_{1},v_{2},...,v_{k}$, and for each child we are given a maximal valid solution for the MMDP feasibility test on its subtree. We would like to produce a maximal valid solution for the feasibility test on $v\text{'s subtree}$.
Denote by $P_{1},...,P_{k}$ the solutions for the feasibility test on each subtree rooted at a child of $v$.
For any subtree of $T$ rooted at node $r$, and a valid solution $P$ for the MMDP feasibility test on the subtree, we call a node $u\in P$, s.t. $d(r,u)\leq\frac{\lambda}{2}$, a \textcolor{blue}{blue} node of the subtree. We call the vertex in $P$ that is closest to $r$, but isn't blue, \textcolor{green}{green}.
Note that each $P_{i}$ contains at most one blue vertex and one green vertex.

\paragraph{The recursion step} Given $P_{1},...,P_{k}$, we would like to produce a solution for $v$'s subtree.
\begin{enumerate}
\item Put in $P$ all the vertices in $P_{1},...,P_{k}$, except for the blue vertices.
\item Take all blue nodes $u$ s.t. $d(u,v)> \frac{\lambda}{2}$
\item Take $u'$, the blue node farthest from $v$ s.t. $d(u',v)\leq \frac{\lambda}{2}$, if it exists, and if $d(u',x)\geq \lambda$, where $x$ is the closest node to the root $v$ we have chosen so far.
\item Decide whether to take $v$ (the root) to the solution by looking at the closest vertex to it we have already put in $P$.
\end{enumerate}


\begin{definition}
\emph{Active and Inactive nodes} We will call a vertex $v$ of the tree \emph{inactive} if there is a vertex $u$ we already chose to be in $P$, s.t $d(u,v)<\lambda$. We will call $v$ \emph{active} if there is no such vertex $u$ and $v \notin P$.
\end{definition}
\begin{lemma} \label{greenNodesLemma}
For any subtree of $T$ rooted at node $r$, let $u$ be the most distant active vertex from $r$ in the subtree. Assume $P$ is a maximal subset of the vertices of the subtree s.t. $f(P)\geq\lambda$ and assume $u \notin P$. Denote the closest vertex to $u$ in $P$ by $u'$. Then, if $d(u,r)\ge\frac{\lambda}{2}$, and $P' := P \setminus \lbrace u' \rbrace \cup \lbrace u \rbrace$, it holds that $f(P')\geq\lambda$.
\end{lemma}
\begin{proof}
Assume for contradiction that $f(P')<\lambda$. We assume that we cannot replace $u'$ with $u$ and still get a valid solution. This means that there is a vertex $x \neq u'$, s.t. $x\in P$ and $d(u,x)<\lambda$. 
We know that:
\observation{ $d(r,u)\ge\frac{\lambda}{2}$ (by definition)}
\observation{ $d(u,u')<\lambda$ (because otherwise we could definitely add $u$ to the solution, as $u'$ is defined as closest to $u$ in $P$)}
\observation{ $d(x,u')\ge\lambda$ (since $x$ and $u'$ are both in $P$)}
\observation{ $d(x,u)<\lambda$ (by definition)}
%\corollary{\label{corol5} $d(r,u)>d(r,u')$ (since otherwise $u$ is not the active vertex most distant from $r$).}
\\ {\normalfont Let us look at the possible cases:
\begin{enumerate}
\item \textit{Both $u'$ and $x$ are in the subtree rooted at $r$:}
Because $u$ is the lowest active node in $r$'s subtree, it cannot be an ancestor of $u'$ or $x$.
Let $z=lca(u,u')$. We know that $d(u,z)\geq d(u',z)$ (because $u$ is farther from $r$ than $u'$). Observe the possible cases:
\begin{enumerate}
\item \emph{The path from $u$ to $x$ passes through $z$:}
\begin{enumerate}
\item \emph{The path from $u'$ to $x$ passes through $z$:}
$\lambda> d(u,x) = d(u,z) + d(z,x) \geq d(u',z)+d(z,x) = d(u',x)$ in contradiction to observation 3.
\item \emph{The path from $u'$ to $x$ does not pass through $z$:}
Let $z'=lca(u',x)$. In this case $x$ is also a descendant of $z$ (because u' is a descendant of $z$ by definition and otherwise the path from $x$ to $u'$ would go through $z$). Thus, $d(x,z) \leq d(u,z)$ (since $u$ is the lowest active node). $z'$ is a descendant of $z$, which implies that $d(x,z) \geq d(x,z')$. We know that $\lambda \leq d(x,u') = d(x,z')+d(z',u)$, so we get that $d(x,z') \geq \frac{\lambda}{2}$ (since $d(x,z')\geq d(z',u)$ because $u'$ is closer to $u$ than $x$ by definition). Thus, we have that $d(u,z) \geq d(x,z) \geq d(x,z')\geq \frac{\lambda}{2} \Rightarrow d(u,x) = d(u,z)+d(z,x) \geq \lambda$ in contradiction to observation 4.
\end{enumerate}
\item \emph{The path from $u$ to $x$ does not pass through $z$:}
In this case $z':=lca(u,x)$ must be on the path from $u$ to $z$. It holds that $d(x,z')\leq d(u,z')$.
Also, $\lambda \leq d(u',x) \leq d(u',z')+d(x,z') \leq d(u',z')+d(u,z') = d(u',u)$ in contradiction to observation 2.
\end{enumerate}

\item \textit{$u'$ is in the subtree, and $x$ is not:}
This means that the paths from $u$ and $u'$ to $x$ go through $r$. We have that $d(r,u) \geq d(r,u')$ (since otherwise $u$ is not the active vertex most distant from $r$), which implies that $d(r,u)+d(r,x) \geq d(r,u')+d(r,x)\Rightarrow d(u,x) \geq d(u',x)$ in contradiction to observations 3 and 4.

\item \textit{$x$ is in the subtree and $u'$ is not:}
In this case we know that the paths from $u'$ to $x$ and $u$ go through $r$.
This means that $d(u,u') = d(u,r)+d(r,u')$ and $d(x,u') = d(x,r)+d(r,u')$ $\Rightarrow d(x,r)>d(u,r)$ (because by observation 2 and 3 $d(x,u')>d(u,u')$), but this is a contradiction to $u$ being the lowest active node in the subtree rooted at $r$.

\item \textit{Both $x$ and $u'$ are not in the subtree:}
In this case the paths from $u$ to $u'$ and $x$ got through $r$. $d(u,u') = d(r,u)+d(r,u') < \lambda$ (due to observation 2) $\Rightarrow d(r,u')<\frac{\lambda}{2}$ (due to observation 1). In addition we have that $d(u,x) = d(r,u)+d(r,x) < \lambda$ (due to observation 4) $\Rightarrow d(r,x)<\frac{\lambda}{2}$. It is clear that $d(u',x) \leq d(u',r)+d(r,x) < \lambda$ in contradiction to observation 3.
\end{enumerate}
}
\end{proof}
%TODO add a drawing for each case
Lemma \ref{greenNodesLemma} implies the correctness of the algorithm.
%TODO extend proof of correctness


\subsection{Sublinear feasibility test for the MMDP}
The main idea here is partitioning the tree to fragments and preprocessing them, so that in query time we can process fragments in sub-linear time. We will assume the tree is binary. \footnote{Notice that throughout our algorithm we process caterpillars, and do not consider taking spine nodes to our solution. This is okay, since we can add some artificial nodes with zero-weighted edges. This is also how we handle non-binary trees.}
\subsubsection{Tree Partitioning}\label{tree partitioning}
We would like to have fragments of size $b=log^2n$, s.t. each fragment will be connected to the rest of the tree by at most two vertices. Each fragment has at most $2b$ vertices, and will be defined by its border vertices $u$ and $v$, s.t. $v$ is a descendant of $u$. The fragment will consist of $u$'s subtree without $v$'s subtree. We call the path from $u$ to $v$, the fragment's \textit{spine}, and $v$'s subtree the \textit{hole} of the fragment. %TODO add figure
\begin{lemma}\label{basic partitioning lemma}
For any binary tree on $n$ nodes and a parameter $b$, there is a partition of the tree into $O(n/b)$ such fragments of size at most $2b$.
\end{lemma}
\begin{proof}
Call a node $u$ \textit{large} if the size of its subtree is greater than b and \textit{small}
otherwise. Consider the tree $T_L$ induced by the large nodes of the original tree. Make each leaf in $T_L$ a new fragment with no hole. This creates $O(n/b)$ fragments since each leaf of $T_L$ is the root of a subtree of size at least $b$ in the original tree, and so we have at most $O(n/b)$ leaves in $T_L$. The size of each of these fragments is at most $2b$, since we assume that the tree is binary.
Next, for every branching node in $T_L$, make it a fragment consisting of just one node. This also creates $O(n/b)$ fragments, since in any tree the number of branching nodes is at most the number of leaves. We could not have simply gone up the tree and cut fragments of size $b$, since this would create fragments with more than two boundary nodes.
Ignoring the fragments we have already created, we are left with nodes that form unary chains in $T_L$. Each of these nodes might also have a child that is a small node. We have $O(n/b)$ of these subgraphs (because each of them is defined by two of the previously defined fragments). We scan each of these subgraphs' large nodes bottom-up, and greedily cut them. Clearly these fragments are of size at most $2b$. Denote the size of subgraph $i$, as $b_i$. The number of fragments we created in this phase is at most $$\sum_{i=1}^{n/b} \left\lceil \frac{b_i}{b} \right\rceil \leq \frac{n}{b}$$
In total we have created $O(n/b)$ fragments, each of which is of size at most $2b$.
\end{proof}
This partitioning is done in $O(n)$ time.
We now would like to pre-process the fragments s.t. we can later check in constant time for any two nodes in a fragment, $u_1,u_2$ if $d(u,v)\geq\lambda$, and if $d(u_1,u_2) \leq \frac{\lambda}{2}$, for any possible $\lambda$. We achieve this for most of the fragments.

\subsubsection{Pre-Processing Fragments} \label{Pre-Processing Fragments}
For each fragment, we would like to implicitly construct matrices of total side length (number of rows and columns) $O(blogb)$, that are row and column sorted, and contain all pairwise distances in the fragment.

\begin{definition} \textbf{Centroid Decomposition} %TODO citation?
Given a binary tree, we can find its \textit{centroid} node in linear time. This node divides the tree into three pieces, each of which has no more than half of the nodes of the entire tree. Recursing on each of the pieces will produce the centroid decomposition.
\end{definition}

Apply the centroid decomposition on each fragment. Now, run the following recursive routine: at each level of the recursion, we are given 3 pieces, and for each of them a sorted list of the distances to the inner centroid. We would like to compute a sorted list of distances of all nodes of the current piece to the current centroid. Let us look at one of the three pieces we have already processed. It contains three pieces of its own. For two of these pieces, it holds that all paths from a node inside them to the outer centroid passes through the inner centroid. We call the third piece, for which this does not hold a \textit{problematic} piece. For the two pieces that are not problematic, we can add to all the entries of the lists we have, the distance from the inner centroid to the outer centroid, and then merge the two sorted lists. This is all done in linear time.\\
Our only problem now is the piece where the paths to the outer centroid do not go through the inner one. But notice that if you go one step deeper in the recursion you can see the inside the problematic piece there are two pieces that are not problematic, and we can do the same for their two list and so on. This recursive routine will also take linear time. All together we have $O(logb)$ levels of recursion, and spend linear time on each one, so we get a running time of $O(blogb)$, and $O(nloglogn)$. for all fragments.\\
Now we have for level $i$ of the recursion $3^i$ centroids, and for each of them a sorted list of the distances to it from all nodes in its piece. We could find any pairwise distance in a piece by adding two entries of this list. Since the lists are sorted, we can look at the situation as if we have $3^i$ matrices of and their total side length is $n$ \footnote{We cannot actually afford to explicitly store these matrices, but that is not needed.}. These matrices contain all pairwise distances in all the fragments. Note that we also have some entries in the matrices that do not actually represent pairwise distances in the tree, but that does not matter.
Since we would like to also answer queries for $\frac{\lambda}{2}$, we do the same process for matrices that contain twice the distance in every entry of the original matrices.\\

Now, we can use Frederickson's serching algorithm to eliminate entries of the matrices. Using this searching method, we find the interval of possible solutions to the dispersion problem, $[\lambda_1,\lambda_2)$, s.t. the $\lambda^*$ we are searching for, is in this interval, $\lambda_1$ is the largest number we know is feasible, and $\lambda_2$ is the smallest number we know is not feasible.\\
We call fragments that do not contain a pairwise distance that is in the interval \textit{inactive}, and all other fragments \textit{active}.
For this search, we use theorem 2.1 in \cite{Frederickson1991}:
\begin{theorem}\label{Frederickson's theorem}
Let $M$ be a collection of $N$ sorted matrices ${M_l, M_2, . . . , M_N}$ in which matrix $M_j$ is of dimension $m_j \times nj$, $mj \leq nj$, and $\sum_{j=1}^{N} mj = m$.
Let p be nonnegative. The number of feasibility tests needed to discard all but at most p of the elements is $O(max \lbrace log (max_j \lbrace nj \rbrace), log(\frac{m}{p+1}) \rbrace )$, and the total running time exclusive of feasibility tests is $O(\sum_{j=1}^{N} m_j \times 1og(2n_j/m_j))$.
\end{theorem}
In our case $m=blogb \times \frac{n}{b} = nlogb$ (since for each of the $\frac{n}{b}$ fragments, we have $logb$ levels of the centroid decomposition, and at level we have the distance of every node to a centroid) and we set $p$ to be $n/b^2$. The theorem implies that we can use $O(logb)$ feasibility tests and discard all but $n/b^2$ elements of the matrices. We also pay $O(nlogb)$ exclusive of the feasibility tests. This means that we have at most $n/b^2$ active fragments (out of all $n/b$ fragments). \\
For inactive fragment, it is clear that we can now answer queries checking whether some pairwise distance inside the fragment is at least $\lambda$, or if it is at most $\frac{\lambda}{2}$ \footnote{We can easily compute any pairwise distance in the tree in $O(1)$ time by pre-computing all distances to the root of the tree, and using LCA queries.}.

Active fragments, will be processed as in the linear algorithm described before, so we can ignore them for now.

We now do the following pre-processing for each inactive fragment:
\begin{step}
\textbf{reduce the fragment to a caterpillar:}
Observe that each fragment is comprised of its spine, and the subtrees hanging off of it. Using queries on pairwise distances as described above, we can use our linear feasibility test on the subtrees hanging off the spine, and get a blue and a green node for each of them. This is done in linear time.\\
Our fragment is now reduced to caterpillar with a blue child and a green child for every spine node.
\end{step}
\begin{step}\label{removing green nodes}
\textbf{Find the blue nodes that will certainly not be taken:}
Let the $i$-th leaf be connected by an edge of length $y_i$ to a spine node at distance $x_i$ from the root of the caterpillar. Order the leaves so that $x_1 < x_2 < ... < x_k$.
Some of the blue nodes can be ignored as they "collide" with green nodes. We start by finding the closest green node to each blue node. We can do this in linear time by scanning the caterpillar bottom-up, while saving for each blue node, the closest green node below it and the distance to it. We then do the same scan from top to bottom, and from both scans combined, we get for each blue node the closest green node and the distance to it. Now we want to find the blue nodes that are too close to a green node. We can do this since we are looking at an inactive fragment, and so a pairwise distance in it must be either smaller than $\lambda_1$ or greater or equal to $\lambda_2$. Delete all blue nodes for which the distance to the closest green node is smaller than the new $\lambda_1$. 
Now we are only left with some of the blue nodes to consider, and for all of them it hold that $y_i < \lambda_1/2$ (otherwise they would be green), and from this point we can ignore the green nodes.
\end{step}
\begin{step}
\textbf{Prune the caterpillar so that the leaves' distances to the root are non-decreasing:}\label{making distances from the root monotone}
Traverse the caterpillar from bottom to top. Observe the $i$-th leaf, $u$. Denote by $v$ the leaf above $u$, and let  $j=i-1$. Assume $x_j+y_j > x_i+y_i$ (i.e $v$ is farther from the root than $u$). We get that $x_i-x_j+y_i < y_j$. $d(u,v) = x_i-x_j+y_i+y_j < 2y_j < \lambda$. So an optimal solution cannot contain both $u$ and $v$. If $u$ is in the solution we can replace it with $v$. This can be done because $v$ is farther away from any node above it than $u$, and $u$ is closer to any node below it than $v$. Let $v'$ be a leaf node above $v$, then $d(v,v') - d(v',u) \geq y_j-(x_i-x_j)-y_i = x_j+y_j-(x_i+y_i) > 0$, and the reasoning for the second case is similar.
So in fact, we can remove the i-th leaf from the caterpillar.
\end{step}
\begin{step}
\textbf{Prune the caterpillar so that the leaves' distances to the bottom are non-decreasing:} \label{making distances from the hole monotone}
This is done as in the previous step.
\end{step}
\begin{step}
\textbf{Compute the solution for any possible value of the nearest chosen node in the hole:}
In query time we will want to process each fragment after its hole has already been processed.\\
We call a set of consecutive leaves of the caterpillar, that contains the closest leaf to the hole, a \emph{suffix} of the caterpillar. Similarly we can define the caterpillar's \emph{prefix}.\\
Assuming we know what is the closest chosen node in the fragment's hole, we can eliminate an entire suffix of the caterpillar (because of the monotonicity of the distances of blue nodes from the hole). We can compute in preprocessing, for any possible eliminated suffix, which nodes in the fragment should be chosen, and also which nodes are the blue and green node (and also the number of chosen nodes) we need to pass to the next fragment.\\
In order to pre-compute this, scan the caterpillar from top to bottom. For every possible prefix of the caterpillar we would like to store the numbers of nodes chosen, the green node and the blue node, assuming all nodes that are not in the prefix are eliminated as they are too close to the hole. Observe the bottom node of the current prefix. If the distance of this node to the fragment's root is less than $\frac{\lambda}{2}$\footnote{We do not actually know $\lambda$ in preprocessing, but due to the previous steps, such a query of a node inside the fragment would produce the same result for any possible $\lambda$.}, store it as the blue node, zero as the number of chosen nodes, and NULL as the green node (if this fragment has a hole you also need to consider its blue and green node). Else, (the node's distance to the root is more than $\frac{\lambda}{2}$), write it as the green node. Then, use binary search to find the node closest to it, that is at distance of at least $\lambda$. Add 1 to the number of chosen nodes stored in the node you found, and either store it as the blue node, or copy the blue node stored there. This would take $O(blogb)$ time. We can improve this by not binary searching for the first node far enough, but instead saving it for each prefix, and then only going down from the previous node found. This would only take $O(b)$ time.
\end{step}

\subsubsection{Feasibility Test}
We now scan the whole tree, and for each inactive fragment we would like to produce in $O(logb)$ time: the number of chosen nodes in the fragment, the blue node, and the green node. In this procedure we use the caterpillars we have created in the preprocessing. Notice that now we are given $\lambda$.
We run this procedure bottom-up, so we assume the fragments rooted at the hole of the current one have already been processed.\\
Denote the root of the fragment, $r$, the hole's blue node, $u$, and the current fragment's leaf farthest from $r$, $v$.\\
\begin{case}
\textbf{$d(r,v) < \frac{\lambda}{2}$:} Because of the monotonicity of the distances of leaves from the root, every leaf of the caterpillar is closer to $r$ than $v$, so we return $u$ as the blue node, and the hole's green node, and number of chosen nodes. If $v$ is farther from $r$ than $u$ (which is possible, because the monotonicity only holds inside each fragment), we set it to be the new blue node (since it would also be farther from any node in the hole than $u$).
\end{case}
\begin{case}
\textbf{$d(r,v) \geq \frac{\lambda}{2}$:}
In this case we need to consider the suffixes of the current fragment. If $v$ is farther from $r$ than $u$, we set it as the blue node. We compute the suffix of the fragment that cannot be taken. We can do this by binary searching for the first node of the fragment that is at distance at least $\lambda$ from the current blue node. We have pre-computed all we need to know once we have the relevant prefix.
\end{case}
Each feasibility test will cost us $O(logb)$ for each inactive fragment, and $O(b)$ for each active one. In total $O(\frac{n}{b} \times logb) + O(\frac{n}{b^2} \times b) = O(\frac{nloglogn}{log^2n})$.


\subsection{O(nloglogn) Solution for the Dispersion problem} \label{nloglogn solution}
The general idea of the algorithm is using the heavy path decomposition. We are searching for $\lambda^*$, which is the distance between some two nodes in the tree, and the largest number for which a feasibility test would return true.
We go through the heavy path tree bottom-up, and process all heavy paths at a specific level in parallel, until we are left with a green and blue node for each of them. We maintain an interval $[\lambda_1,\lambda_2)$ as we previously did. The interval will get smaller and smaller throughout the run.

We now describe the processing of a heavy path, which is very similar to the preprocessing of inactive fragments presented in \ref{Pre-Processing Fragments}. Notice that the traversal is bottom-up, so we have already processed all of the path's children in the heavy path tree. Because we have determined $\lambda^*$ with sufficient accuracy (i.e. reduced the size of the maintained interval), each subtree hanging off a heavy path can be replaced by its blue and green node attached by single edges to the heavy path. Hence, each such heavy path is a caterpillar, with one or two children for each spine node. We would like to be able to find the green and blue nodes for the current heavy path. %The situation is illustrated in figure %TODO add a figure
Assume that the caterpillar has k nodes. As we defined before, Let the $i$-th leaf be connected by an edge of length $y_i$ to a spine node at distance $x_i$ from the root of the caterpillar, and order the leaves so that $x_1 < x_2 < ... < x_k$.

\begin{step}
\textbf{Find the blue nodes that will certainly not be taken:}
This is done as in step \ref{removing green nodes}.
\end{step}
\begin{step}
\textbf{Prune the caterpillar so that the distances of leaves from the root and the hole are monotone:}
This is done as in steps \ref{making distances from the root monotone} and \ref{making distances from the hole monotone}.
\end{step}
\begin{step}
\textbf{Construct a row and column sorted matrix storing all pairwise distance in the caterpillar}
We have obtained a caterpillar with one child for every spine node, s.t the distances of leaves are monotone. It is easy to see that arranging the matrix in the natural order will produce a triangular matrix with monotone rows and columns \footnote{Again, we cannot afford to explicitly store this matrix, but we can instead store the distances from all nodes of the fragment to the centroid node.}.
\end{step}
\begin{step}
\textbf{Run a searching algorithm on the sorted matrices of all the heavy paths at the current level}
We now use theorem \ref{Frederickson's theorem} to search the sorted matrices containing all pairwise distances in the heavy paths of the current level. We need to eliminate all of the entries, and so we set $p$ to zero. We thus narrow down our interval $[\lambda_1,\lambda_2)$ so that it does not contain any pairwise distance in the caterpillar. Now, we can use the same bottom up procedure we used for the linear feasibility test in subsection \ref{linear F.T.}, and produce a blue and a green node of the caterpillar that will be valid for any value of $\lambda^*$.
\end{step}
Since the number of vertices in the heavy paths of the current level is at most $n$, we need to use $O(logn)$ feasibility tests for each level. There are at most $logn$ levels in the heavy path tree, so we use $O(log^2n)$ calls to our sublinear feasibility test in total. This yields a time complexity of $O(nloglogn)$ (the time needed for the search exclusive of the feasibility tests is linear). \\
After processing all heavy paths we finally have a maximal valid solution for the whole tree.


\subsection{$\textbf{O(nlog*n)}$ Algorithm}
The high level idea of the $O(n \log \log n)$ algorithm was dividing the input tree into fragments, and preprocessing them using the linear feasibility test (f.t.) to get a sublinear one. In order to get the complexity down to $O(n \log ^*n)$ we will use a similar process, iteratively, with growing framents size, improving in each iteration the performance of our f.t.
We start with fragments of size $c^3$ for some constant $c$.
We pay $O(n)$ time for preprocessing and get an $O(\frac{n}{c^3} \times \log c)$ time f.t.
We use this f.t. to do the same preprocessing again, this time with fragments of size $(2^c)^3$.
We will now achieve $O(\frac{n}{2^{3c}} \times c)$ time for f.t.
We do this for $\log ^*n$ iterations until we get to fragments of size $\log ^3n$, and have an f.t. of $O(\frac{n \log \log n}{\log ^3n})$.
Since we do $\log ^*n$ iterations and linear time work for each of them the total preprocessing is in $O(n \log ^*n)$ time.\\
We now describe one iteration of this process.
Assuming we have obtained an f.t. of $O(\frac{n}{b^3} \times \log b)$ from the previous step, we now partition the tree to fragments of size $B^3$ (as in \ref{tree partitioning}), where $B:=2^b$. We perform a heavy path decomposition on each fragment, and go over the the heavy path trees of the fragments bottom up and in parallel. The paths at lower levels have been processed s.t. each of them is reduced to a blue and a green node, and so each current path is a caterpillar, that we will now reduce to two nodes by using Frederickson's method. As we have seen in \ref{nloglogn solution}, we can create, in linear time, a matrix with linear number of rows and columns that contains all pairwise distances of a path at the current level. We construct each matrix by pruning the caterpillars so that the distances of leaves from the root and the hole are monotone, thus achieving a matrix that is row and column sorted. We have $n/B^3$ matrices of size at most $B^3$ (since each heavy path contains at most all the vertices of the fragment). We use Frederickson's searching method, with the parameters $m:=n$ and $p:=\frac{n}{B^4}$. We thus need to use the f.t. $O(\log (\frac{n}{\frac{n}{B^4}}))=O(\log B)$ times, and an extra linear processing time exclusive of the feasibility tests. We Compute the blue and green node of each path as we did before, and continue up in the heavy path trees, until we are left with only the top heavy path of each fragment. Since $p>0$, during this preprocessing, some fragments become active. Once a fragment becomes active we stop its preprocessing.\\
After the preprocessing is done, we have at most $\log B \times \frac{n}{B^4}$ active fragments (because we do not eliminate at most $p$ pairwise distances at each level), which we will process in linear time in the new f.t. For all other fragments we have obtained a pruned caterpillar, so that we can in linear time pre-compute the required information for any possible eliminated suffix as described in \ref{Pre-Processing Fragments}. We will process these inactive fragments in logarithmic time in the new f.t. Thus we have obtained an f.t. of $O(\frac{n}{B^3} \times \log B)$.\\
We do this iteratively until we have an f.t. of $O(\frac{n}{\log ^3n} \times \log \log n)$, and then use it solve the dispersion optimization problem in linear time (in the same manner as in each of the previous $\log ^*n$ phases).\\
In total, for all $O(\log B)$ levels of the heavy path trees, we used $O(\log ^2B)$ calls to the previous f.t., that cost $(\log ^2B \times \frac{n}{b^3} \times \log b)=O(\frac{n}{b} \times \log b)$ which is less than linear time. In addition at each step we used linear time for the decompositions, so in total $O(n \log ^*n)$. 

\subsection{Linear time solution for the Dispersion Optimization Problem}
Our linear algorithm is based on the $O(n \log ^*n)$ algorithm we have presented. In order to achieve linear time in total we cannot afford to partition the input tree to fragments independently for each fragment size.



\bibliographystyle{alpha}
\bibliography{dispersion}



\end{document}